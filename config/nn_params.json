{
    "input_dim": null,
    "hidden_layers": [
        64,
        32
    ],
    "output_dim": null,
    "activation": "relu",
    "output_activation": "softmax",
    "learning_rate": 0.01,
    "batch_size": 32,
    "epochs": 10,
    "use_dropout": false,
    "dropout_rate": 0.2,
    "use_batch_norm": false,
    "l2_regularization": 0.0001,
    "optimizer": "adam",
    "early_stopping": true,
    "early_stopping_patience": 5,
    "reduce_lr_on_plateau": false,
    "lr_reduction_factor": 0.1,
    "lr_reduction_patience": 3
}